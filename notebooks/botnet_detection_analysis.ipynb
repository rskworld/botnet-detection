{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Botnet Detection Analysis\n",
        "\n",
        "<!--\n",
        "Project: Botnet Detection with Machine Learning\n",
        "Category: ML Projects\n",
        "Developer: RSK World\n",
        "Founder: Molla Samser\n",
        "Designer & Tester: Rima Khatun\n",
        "Contact: help@rskworld.in, support@rskworld.in\n",
        "Phone: +91 93305 39277\n",
        "Address: Nutanhat, Mongolkote, Purba Burdwan, West Bengal, India, 713147\n",
        "Website: https://rskworld.in\n",
        "-->\n",
        "\n",
        "This notebook provides comprehensive analysis of network traffic data for botnet detection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add scripts directory to path\n",
        "sys.path.append('../scripts')\n",
        "from feature_extractor import FeatureExtractor\n",
        "from data_processor import DataProcessor\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Explore Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "data_path = '../data/processed/training_data.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data info\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check class distribution\n",
        "if 'is_botnet' in df.columns:\n",
        "    print(\"Class Distribution:\")\n",
        "    print(df['is_botnet'].value_counts())\n",
        "    print(f\"\\nBotnet ratio: {df['is_botnet'].mean():.2%}\")\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    df['is_botnet'].value_counts().plot(kind='bar', color=['green', 'red'])\n",
        "    plt.title('Class Distribution')\n",
        "    plt.xlabel('Is Botnet')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks([0, 1], ['Normal', 'Botnet'], rotation=0)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract features\n",
        "feature_extractor = FeatureExtractor()\n",
        "df_features = feature_extractor.extract_features(df)\n",
        "\n",
        "print(f\"Original features: {len(df.columns)}\")\n",
        "print(f\"Extracted features: {len(df_features.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select features for modeling\n",
        "X, y = feature_extractor.select_features(df_features)\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape if y is not None else 'None'}\")\n",
        "print(f\"\\nFeatures: {list(X.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis\n",
        "if y is not None:\n",
        "    X_with_target = X.copy()\n",
        "    X_with_target['is_botnet'] = y\n",
        "    \n",
        "    plt.figure(figsize=(12, 10))\n",
        "    correlation = X_with_target.corr()\n",
        "    sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
        "    plt.title('Feature Correlation Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature distributions\n",
        "if y is not None and len(X.columns) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    for idx, col in enumerate(X.columns[:4]):\n",
        "        normal_data = X[y == 0][col]\n",
        "        botnet_data = X[y == 1][col]\n",
        "        \n",
        "        axes[idx].hist(normal_data, alpha=0.5, label='Normal', bins=30)\n",
        "        axes[idx].hist(botnet_data, alpha=0.5, label='Botnet', bins=30)\n",
        "        axes[idx].set_xlabel(col)\n",
        "        axes[idx].set_ylabel('Frequency')\n",
        "        axes[idx].set_title(f'Distribution of {col}')\n",
        "        axes[idx].legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "if y is None:\n",
        "    # Create synthetic target if not available\n",
        "    y = (X.iloc[:, 0] > X.iloc[:, 0].median()).astype(int)\n",
        "\n",
        "# Remove NaN\n",
        "mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
        "X_clean = X[mask]\n",
        "y_clean = y[mask]\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean\n",
        ")\n",
        "\n",
        "print(f\"Training set: {len(X_train)} samples\")\n",
        "print(f\"Test set: {len(X_test)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "print(\"Model Performance:\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted', zero_division=0):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, y_pred, average='weighted', zero_division=0):.4f}\")\n",
        "print(f\"F1-Score:  {f1_score(y_test, y_pred, average='weighted', zero_division=0):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Normal', 'Botnet'],\n",
        "            yticklabels=['Normal', 'Botnet'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Importance\n",
        "if hasattr(model, 'feature_importances_'):\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X_train.columns,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\n",
        "    plt.title('Top 10 Feature Importance')\n",
        "    plt.xlabel('Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nTop 10 Most Important Features:\")\n",
        "    print(feature_importance.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary\n",
        "\n",
        "This analysis demonstrates:\n",
        "- Network traffic data exploration\n",
        "- Feature extraction and engineering\n",
        "- Machine learning model training\n",
        "- Performance evaluation\n",
        "- Feature importance analysis\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
